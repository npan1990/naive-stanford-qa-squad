{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "555ee83a-935d-4ce4-8fa1-9523bb840727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2024, Nikolaos Panagiotou, npan1990@gmail.com\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#     http://www.apache.org/licenses/LICENSE-2.0\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aefd2f60-77c7-445e-92c9-2a9483c34fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "import transformers\n",
    "import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from transformers import AutoModelForQuestionAnswering, AutoTokenizer, pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b3a9ff-e65e-4d14-b5ee-c7117128b993",
   "metadata": {},
   "source": [
    "# Evaluate SQUAD\n",
    "\n",
    "This is a notebook that helps the evaluation of the SQUAD dev set using custom fine tuned approaches.\n",
    "This is a simplistic implementation of F1 and EM scores and can not be directly comparred to the original scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "02c14ae0-113d-4408-b15c-38faeaa20a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEV_FILE = '../data/squad/dev-v2.0.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c17b9b9-99d8-4d8f-bd03-47082ff75c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "devset_d = json.load(open(DEV_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e17443e3-353a-4017-be45-de0e035942e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "devset_df = pd.DataFrame(devset_d['data'])\n",
    "devset_df['paragraphs_number'] = devset_df['paragraphs'].str.len()\n",
    "devset_df['doc_id'] = range(1,devset_df.shape[0]+1)\n",
    "paragraphs_devset_df = devset_df.explode(['paragraphs'])\n",
    "paragraphs_devset_df['paragraph_id'] = range(1,paragraphs_devset_df.shape[0]+1)\n",
    "paragraphs_devset_df['qa'] = paragraphs_devset_df.apply(lambda x: x['paragraphs']['qas'], axis=1)\n",
    "paragraphs_devset_df['context'] = paragraphs_devset_df.apply(lambda x: x['paragraphs']['context'], axis=1)\n",
    "paragraphs_devset_df['number_qa'] = paragraphs_devset_df['qa'].str.len()\n",
    "\n",
    "q_devset_df = paragraphs_devset_df.explode(['qa'])\n",
    "q_devset_df['question'] = q_devset_df.apply(lambda x: x['qa']['question'], axis=1)\n",
    "q_devset_df['answers'] = q_devset_df.apply(lambda x: x['qa']['answers'], axis=1)\n",
    "q_devset_df['answers_number'] = q_devset_df['answers'].str.len()\n",
    "\n",
    "qa_devset_df = q_devset_df.explode(['answers'])\n",
    "positive_qa_devset_df = qa_devset_df[~qa_devset_df['answers'].isnull()].copy()\n",
    "positive_qa_devset_df['answer'] = positive_qa_devset_df.apply(lambda x: x['answers']['text'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e21af381-b1b6-49d1-8691-bfa16bdc8f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For custom model\n",
    "checkpoint = 'npan1990/squad-distil-bert'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(checkpoint).to('cuda:0')\n",
    "tokenizer = AutoTokenizer.from_pretrained('distilbert-base-uncased')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eddf99df-b08b-4801-b70a-1de0d4bb7f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pretrained model\n",
    "checkpoint = 'distilbert/distilbert-base-cased-distilled-squad'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(checkpoint).to('cuda:0')\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dd18bbb6-4ef7-4269-9723-f64e43187942",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForQuestionAnswering were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['qa_outputs.weight', 'qa_outputs.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# for distilbert model\n",
    "checkpoint = 'distilbert-base-uncased'\n",
    "model = AutoModelForQuestionAnswering.from_pretrained(checkpoint).to('cuda:0')\n",
    "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe357c3-beee-4ba2-956c-7fee3c2ec8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "question_answerer = pipeline(\"question-answering\", model=model, tokenizer=tokenizer, device='cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8a9a4bb6-3032-4fa2-b39d-c0bf5ac788f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "questions = []\n",
    "for index,row in positive_qa_devset_df.iterrows():\n",
    "    questions.append(\n",
    "        {'context': row['context'],\n",
    "         'question': row['question']})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a129fa1-380c-4dd3-a34d-7b9c389649f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = question_answerer(questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ddab28b0-e8ab-43db-b211-7d6a552e371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_qa_devset_df['predicted_answer'] = [answer['answer'] for answer in answers]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ba04cb-c292-448a-a9f6-07d9bb19039d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_all_metrics(predicted_answers, correct_answers):\n",
    "    f1s = []\n",
    "    ems = []\n",
    "    for i in range(len(predicted_answers)):\n",
    "        predicted_answer = predicted_answers[i]\n",
    "        correct_answer = correct_answers[i]\n",
    "        tokenized_predicted_answer = predicted_answer.split(r'\\s+')\n",
    "        tokenized_answer = correct_answer.split(r'\\s+')\n",
    "\n",
    "        predicted_answer_s = set(predicted_answer)\n",
    "        correct_answer_s = set(correct_answer)\n",
    "\n",
    "        tp = float(len(predicted_answer_s & correct_answer_s))\n",
    "        fp = float(len(predicted_answer_s - correct_answer_s))\n",
    "        fn = float(len(correct_answer_s - predicted_answer_s))\n",
    "\n",
    "        try:\n",
    "            pr = tp / (tp+fp)\n",
    "            rc = tp / len(correct_answer_s)\n",
    "            f1 = 2*pr*rc/(pr+rc)\n",
    "        except ZeroDivisionError:\n",
    "            f1 = 0.0\n",
    "\n",
    "        f1s.append(f1)\n",
    "\n",
    "        if predicted_answer == correct_answer:\n",
    "            ems.append(1)\n",
    "        else:\n",
    "            ems.append(0)\n",
    "\n",
    "    return np.average(f1s), np.average(ems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6d50407a-6e48-4358-971c-fecf865352b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.38472900782734726, 0.00014776869273963155)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_all_metrics(positive_qa_devset_df['predicted_answer'].tolist(),positive_qa_devset_df['answer'].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
